{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4399a303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables and set up auto-reload\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c8d72d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Clarify with User Instructions</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  These are the messages that have been exchanged so far from the user asking for the report:                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Messages&gt;</span>                                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  {messages}                                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Messages&gt;</span>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Today's date is {date}.                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Assess whether you need to ask a clarifying question, or if the user has already provided enough information   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  for you to start research.                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  IMPORTANT: If you can see in the messages history that you have already asked a clarifying question, you       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  almost always do not need to ask another one. Only ask another question if ABSOLUTELY NECESSARY.               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  If there are acronyms, abbreviations, or unknown terms, ask the user to clarify.                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  If you need to ask a question, follow these guidelines:                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Be concise while gathering all necessary information                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Make sure to gather all the information needed to carry out the research task in a concise, well-structured  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  manner.                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Use bullet points or numbered lists if appropriate for clarity. Make sure that this uses markdown            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  formatting and will be rendered correctly if the string output is passed to a markdown renderer.               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Don't ask for unnecessary information, or information that the user has already provided. If you can see     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  that the user has already provided the information, do not ask for it again.                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Respond in valid JSON format with these exact keys:                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"need_clarification\": boolean,                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"question\": \"<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;question to ask the user to clarify the report scope&gt;</span>\",                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"verification\": \"<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;verification message that we will start research&gt;</span>\"                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  If you need to ask a clarifying question, return:                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"need_clarification\": true,                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"question\": \"<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;your clarifying question&gt;</span>\",                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"verification\": \"\"                                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  If you do not need to ask a clarifying question, return:                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"need_clarification\": false,                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"question\": \"\",                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"verification\": \"<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;acknowledgement message that you will now start research based on the provided </span>              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">information&gt;</span>\"                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  For the verification message when no clarification is needed:                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Acknowledge that you have sufficient information to proceed                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Briefly summarize the key aspects of what you understand from their request                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Confirm that you will now begin the research process                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Keep the message concise and professional                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mClarify with User Instructions\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  These are the messages that have been exchanged so far from the user asking for the report:                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Messages>\u001b[0m                                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  {messages}                                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Messages>\u001b[0m                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Today's date is {date}.                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Assess whether you need to ask a clarifying question, or if the user has already provided enough information   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  for you to start research.                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  IMPORTANT: If you can see in the messages history that you have already asked a clarifying question, you       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  almost always do not need to ask another one. Only ask another question if ABSOLUTELY NECESSARY.               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  If there are acronyms, abbreviations, or unknown terms, ask the user to clarify.                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  If you need to ask a question, follow these guidelines:                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Be concise while gathering all necessary information                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Make sure to gather all the information needed to carry out the research task in a concise, well-structured  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  manner.                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Use bullet points or numbered lists if appropriate for clarity. Make sure that this uses markdown            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  formatting and will be rendered correctly if the string output is passed to a markdown renderer.               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Don't ask for unnecessary information, or information that the user has already provided. If you can see     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  that the user has already provided the information, do not ask for it again.                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Respond in valid JSON format with these exact keys:                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"need_clarification\": boolean,                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"question\": \"\u001b[1;34m<question to ask the user to clarify the report scope>\u001b[0m\",                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"verification\": \"\u001b[1;34m<verification message that we will start research>\u001b[0m\"                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  If you need to ask a clarifying question, return:                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"need_clarification\": true,                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"question\": \"\u001b[1;34m<your clarifying question>\u001b[0m\",                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"verification\": \"\"                                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  If you do not need to ask a clarifying question, return:                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"need_clarification\": false,                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"question\": \"\",                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"verification\": \"\u001b[1;34m<acknowledgement message that you will now start research based on the provided \u001b[0m              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34minformation>\u001b[0m\"                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  For the verification message when no clarification is needed:                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Acknowledge that you have sufficient information to proceed                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Briefly summarize the key aspects of what you understand from their request                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Confirm that you will now begin the research process                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Keep the message concise and professional                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import show_prompt\n",
    "from Autonomous_Learning_Agent.prompts import clarify_with_user_instructions\n",
    "show_prompt(clarify_with_user_instructions, \"Clarify with User Instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "138bd586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/Autonomous_Learning_Agent/state_scope.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/Autonomous_Learning_Agent/state_scope.py\n",
    "\n",
    "\"\"\"State Definitions and Pydantic Schemas for Research Scoping.\n",
    "\n",
    "This defines the state objects and structured schemas used for\n",
    "the research agent scoping workflow, including researcher state management and output schemas.\n",
    "\"\"\"\n",
    "\n",
    "import operator\n",
    "from typing_extensions import Optional, Annotated, List, Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# ===== STATE DEFINITIONS =====\n",
    "\n",
    "class AgentInputState(MessagesState):\n",
    "    \"\"\"Input state for the full agent - only contains messages from user input.\"\"\"\n",
    "    pass\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    \"\"\"\n",
    "    Main state for the full multi-agent research system.\n",
    "    \n",
    "    Extends MessagesState with additional fields for research coordination.\n",
    "    Note: Some fields are duplicated across different state classes for proper\n",
    "    state management between subgraphs and the main workflow.\n",
    "    \"\"\"\n",
    "\n",
    "    # Research brief generated from user conversation history\n",
    "    research_brief: Optional[str]\n",
    "    # Messages exchanged with the supervisor agent for coordination\n",
    "    supervisor_messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    # Raw unprocessed research notes collected during the research phase\n",
    "    raw_notes: Annotated[list[str], operator.add] = []\n",
    "    # Processed and structured notes ready for report generation\n",
    "    notes: Annotated[list[str], operator.add] = []\n",
    "    # Final formatted research report\n",
    "    final_report: str\n",
    "\n",
    "# ===== STRUCTURED OUTPUT SCHEMAS =====\n",
    "\n",
    "class ClarifyWithUser(BaseModel):\n",
    "    \"\"\"Schema for user clarification decision and questions.\"\"\"\n",
    "    \n",
    "    need_clarification: bool = Field(\n",
    "        description=\"Whether the user needs to be asked a clarifying question.\",\n",
    "    )\n",
    "    question: str = Field(\n",
    "        description=\"A question to ask the user to clarify the report scope\",\n",
    "    )\n",
    "    verification: str = Field(\n",
    "        description=\"Verify message that we will start research after the user has provided the necessary information.\",\n",
    "    )\n",
    "\n",
    "class ResearchQuestion(BaseModel):\n",
    "    \"\"\"Schema for structured research brief generation.\"\"\"\n",
    "    \n",
    "    research_brief: str = Field(\n",
    "        description=\"A research question that will be used to guide the research.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c529866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/Autonomous_Learning_Agent/research_agent_scope.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/Autonomous_Learning_Agent/research_agent_scope.py\n",
    "\n",
    "\"\"\"User Clarification and Research Brief Generation.\n",
    "\n",
    "This module implements the scoping phase of the research workflow, where we:\n",
    "1. Assess if the user's request needs clarification\n",
    "2. Generate a detailed research brief from the conversation\n",
    "\n",
    "The workflow uses structured output to make deterministic decisions about\n",
    "whether sufficient context exists to proceed with research.\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "from typing_extensions import Literal\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, AIMessage, get_buffer_string\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "\n",
    "from Autonomous_Learning_Agent.prompts import clarify_with_user_instructions, transform_messages_into_research_topic_prompt\n",
    "from Autonomous_Learning_Agent.state_scope import AgentState, ClarifyWithUser, ResearchQuestion, AgentInputState\n",
    "\n",
    "# ===== UTILITY FUNCTIONS =====\n",
    "\n",
    "def get_today_str() -> str:\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    return f\"{now.strftime('%a %b')} {now.day}, {now.year}\"\n",
    "\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "\n",
    "# Initialize model\n",
    "model = init_chat_model(\"google_genai:models/gemini-flash-lite-latest\")\n",
    "\n",
    "# ===== WORKFLOW NODES =====\n",
    "\n",
    "def clarify_with_user(state: AgentState) -> Command[Literal[\"write_research_brief\", \"__end__\"]]:\n",
    "    \"\"\"\n",
    "    Determine if the user's request contains sufficient information to proceed with research.\n",
    "    \n",
    "    Uses structured output to make deterministic decisions and avoid hallucination.\n",
    "    Routes to either research brief generation or ends with a clarification question.\n",
    "    \"\"\"\n",
    "    # Set up structured output model\n",
    "    structured_output_model = model.with_structured_output(ClarifyWithUser)\n",
    "\n",
    "    # Invoke the model with clarification instructions\n",
    "    response = structured_output_model.invoke([\n",
    "        HumanMessage(content=clarify_with_user_instructions.format(\n",
    "            messages=get_buffer_string(messages=state[\"messages\"]), \n",
    "            date=get_today_str()\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Route based on clarification need\n",
    "    if response.need_clarification:\n",
    "        return Command(\n",
    "            goto=END, \n",
    "            update={\"messages\": [AIMessage(content=response.question)]}\n",
    "        )\n",
    "    else:\n",
    "        return Command(\n",
    "            goto=\"write_research_brief\", \n",
    "            update={\"messages\": [AIMessage(content=response.verification)]}\n",
    "        )\n",
    "\n",
    "def write_research_brief(state: AgentState):\n",
    "    \"\"\"\n",
    "    Transform the conversation history into a comprehensive research brief.\n",
    "    \n",
    "    Uses structured output to ensure the brief follows the required format\n",
    "    and contains all necessary details for effective research.\n",
    "    \"\"\"\n",
    "    # Set up structured output model\n",
    "    structured_output_model = model.with_structured_output(ResearchQuestion)\n",
    "    \n",
    "    # Generate research brief from conversation history\n",
    "    response = structured_output_model.invoke([\n",
    "        HumanMessage(content=transform_messages_into_research_topic_prompt.format(\n",
    "            messages=get_buffer_string(state.get(\"messages\", [])),\n",
    "            date=get_today_str()\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Update state with generated research brief and pass it to the supervisor\n",
    "    return {\n",
    "        \"research_brief\": response.research_brief,\n",
    "        \"supervisor_messages\": [HumanMessage(content=f\"{response.research_brief}.\")]\n",
    "    }\n",
    "\n",
    "# ===== GRAPH CONSTRUCTION =====\n",
    "\n",
    "# Build the scoping workflow\n",
    "deep_researcher_builder = StateGraph(AgentState, input_schema=AgentInputState)\n",
    "\n",
    "# Add workflow nodes\n",
    "deep_researcher_builder.add_node(\"clarify_with_user\", clarify_with_user)\n",
    "deep_researcher_builder.add_node(\"write_research_brief\", write_research_brief)\n",
    "\n",
    "# Add workflow edges\n",
    "deep_researcher_builder.add_edge(START, \"clarify_with_user\")\n",
    "deep_researcher_builder.add_edge(\"write_research_brief\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "scope_research = deep_researcher_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "320d1acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile with in-memory checkpointer to test in notebook\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from Autonomous_Learning_Agent.research_agent_scope import deep_researcher_builder\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "scope = deep_researcher_builder.compile(checkpointer=checkpointer)\n",
    "display(Image(scope.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7255e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────────── 🧑 Human ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> I want to research the best coffee shops in San Francisco.                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────────────\u001b[0m\u001b[34m 🧑 Human \u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m I want to research the best coffee shops in San Francisco.                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> To provide you with the best research on coffee shops in San Francisco, could you specify what criteria you are <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> most interested in? For example, are you looking for the best based on:                                         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 1. Ambiance/Seating (e.g., good for working remotely)?                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 2. Coffee quality/Roaster reputation?                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 3. Specific neighborhoods?                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 4. Price range?                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 5. Unique offerings (e.g., pastries, specific brewing methods)?                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m To provide you with the best research on coffee shops in San Francisco, could you specify what criteria you are \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m most interested in? For example, are you looking for the best based on:                                         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 1. Ambiance/Seating (e.g., good for working remotely)?                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 2. Coffee quality/Roaster reputation?                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 3. Specific neighborhoods?                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 4. Price range?                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 5. Unique offerings (e.g., pastries, specific brewing methods)?                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the workflow\n",
    "from utils import format_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "result = scope.invoke({\"messages\": [HumanMessage(content=\"I want to research the best coffee shops in San Francisco.\")]}, config=thread)\n",
    "format_messages(result['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046d5fa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Error calling model 'models/gemini-flash-lite-latest' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 3.273082054s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '3s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3040\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3039\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3040\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3042\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\google\\genai\\models.py:5203\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5202\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5203\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5207\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\google\\genai\\models.py:3985\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3983\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3985\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3986\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   3990\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3991\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1388\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1385\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1386\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1387\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1388\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m response_body = (\n\u001b[32m   1390\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1391\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1222\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1221\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\BoldServices\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\BoldServices\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1201\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1194\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1195\u001b[39m     method=http_request.method,\n\u001b[32m   1196\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1199\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1200\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1203\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1204\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\google\\genai\\errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\google\\genai\\errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 3.273082054s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '3s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[32m      4\u001b[39m thread = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m result = \u001b[43mscope\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mI want to research the best coffee shops in San Francisco Coffee quality/Roaster reputation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m format_messages(result[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\src\\Autonomous_Learning_Agent\\research_agent_scope.py:77\u001b[39m, in \u001b[36mwrite_research_brief\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3149\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3147\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3149\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3150\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3151\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5557\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5550\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5552\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5555\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5556\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5558\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5559\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5560\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5561\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2529\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2526\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2527\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2529\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3044\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3040\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   3041\u001b[39m         **request,\n\u001b[32m   3042\u001b[39m     )\n\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3044\u001b[39m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3046\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Aspire\\Internships\\Projects\\Learning Agent- Group 1\\venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:145\u001b[39m, in \u001b[36m_handle_client_error\u001b[39m\u001b[34m(e, request)\u001b[39m\n\u001b[32m    143\u001b[39m model_name = request.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Error calling model 'models/gemini-flash-lite-latest' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 3.273082054s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '3s'}]}}",
      "During task with name 'write_research_brief' and id '2d6bbb8a-3aa7-cfa4-0e07-66f32bce8c77'"
     ]
    }
   ],
   "source": [
    "# Run the workflow\n",
    "from utils import format_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "result = scope.invoke({\"messages\": [HumanMessage(content=\"I want to research the best coffee shops in San Francisco Coffee quality/Roaster reputation\")]}, config=thread)\n",
    "format_messages(result['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f297dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
